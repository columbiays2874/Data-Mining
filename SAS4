    In the dataset, the variables “Medical School Affiliation” and “region” are categorical variables. “Medical School Affiliation” has two values, “region” has four values so it should be coded as dummy variable. When I add a CLASS statement in some PROCs, I notice that “region” by default is coded as a dummy variable in this way:









    I noticed that the CLASS statement in SAS do not construct the dummy variable in the usual way, because usually if the value equals to 4, the code for the dummy variable should be 0 0 0 instead of -1 -1 -1. In order to tell SAS to recognize the dummy variable when CLASS statement is not allowed, I code the dummy variable in the same way above, adding three more variables V9_1 V9_2 V9_3 after reading the data. Although different coding for dummy variables do not influence the predicted values, the estimates of coefficients and their standard errors are completely different when we code the dummy variable differently. Since there are many questions in this homework that are related to standard errors, I want to say that if someone code the dummy variable in a different way from me, we definitely have different estimates of coefficients and standard errors.

libname lib '/courses/de3a5b65ba27fe300';
data senic;
set lib.senic;
run;

data senic;
set senic;
if V8=1 then V8=0;
if V8=2 then V8=1;
if V9=1 then do;
V9_1=1; V9_2=0; V9_3=0;
end;
if V9=2 then do;
V9_1=0; V9_2=1; V9_3=0;
end;
if V9=3 then do;
V9_1=0; V9_2=0; V9_3=1;
end;
if V9=4 then do;
V9_1=-1; V9_2=-1; V9_3=-1;
end;
run;

1. Use the SENIC data set to perform a logistic regression in which the outcome is medical school affiliation, and the predictors are region, daily census, length of stay, and infection risk.

proc logistic data=senic descending;
class V8 V9;
model V8=V9 V10 V2 V4;
output out=logout predicted=predicted;
run;


What are the standard errors of your estimates of the regression coefficients.
















b. Perform a bootstrap on your regression analysis and find the bootstrap standard errors. How do they compare?

PROC SURVEYSELECT DATA=senic METHOD=URS RATE=1 REPS=113 
OUT=bootdata;
RUN;

ODS OUTPUT parameterestimates=bparameterestimates; 
PROC logistic DATA=bootdata;
BY replicate;
class V8 V9;
MODEL V8 = V9 V10 V2 V4;
RUN;

PROC SORT DATA=bparameterestimates;
BY variable replicate;
RUN;
PROC MEANS DATA=bparameterestimates MEAN STDDEV; 
BY variable;
VAR estimate; 
RUN;








































The standard errors in bootstrap samples are greater than the standard errors of estimates of logistic regression.


2. Carry out a lasso regression with cross-validation on 20% of the data to choose the smoothing parameter of infection risk on all of the other variables.

PROC GLMSELECT DATA=senic;
PARTITION FRACTION(TEST=0.00 VALIDATE=0.20);
class V8 V9;
MODEL V4 = V1 V2 V3 V5 V6 V7 V8 V9 V10 V11 V12 / SELECTION=LASSO(CHOOSE=VALIDATE); 
OUTPUT OUT=lassoout PREDICTED=lassopred;
RUN;

Which variables remain in the model?

  Maybe because the size of the dataset we use is small and we only use 20% of the data to carry out the regression, the results varies when we do the same things many times, sometimes there is only the intercept, and sometimes some variables remain in the model. Here are some examples of different results showing the variables that remain in the model.













b. Is it different if you use Cp to choose the smoothing parameter?

PROC REG DATA=senic;
MODEL V4 = V1 V2 V3 V5 V6 V7 V8 V9_1 V9_2 V9_3 V10 V11 V12 / SELECTION=CP; 
OUTPUT OUT=cpout PREDICTED=cppred;
RUN;

Here are part of the results when we use Cp.





















  We can detect some differences when using different approaches, because it seems that when we use Cp, the model always include V8 or V9 or both, while this does not always happen if we carry out lasso regression.


c. What if you fit a forward regression with XXXX?

PROC REG DATA=senic;
MODEL V4 = V1 V2 V3 V5 V6 V7 V8 V9_1 V9_2 V9_3 V10 V11 V12 /SELECTION=FORWARD; 
OUTPUT OUT=forwardout PREDICTED=forwardpred;
RUN;





















d. Find the sample standard deviation of the fitted values for each approach. How do they compare? Does this comport what you might have expected (explain)?

PROC MEANS DATA=lassoout STDDEV; 
VAR lassopred;
RUN;

PROC MEANS DATA=cpout STDDEV; 
VAR cppred;
RUN;

PROC MEANS DATA=forwardout STDDEV; 
VAR forwardpred;
RUN;


















    Since lasso regression not only selects variables, but also shrinks the regression parameters, we expect the standard errors of lasso estimates to be smaller. The result comports what we have expected.

3. Carry out a ridge regression for the same problem as in part 2 above. Choose a few different values of the ridge parameter.

proc reg data=senic ridge=(0 to 0.6 by 0.05) outest=outest;
MODEL V4 = V1 V2 V3 V5 V6 V7 V8 V9_1 V9_2 V9_3 V10 V11 V12;
run;


































































Explain how to compute the “effective degrees of freedom” for ridge regression.

  The effective degrees of freedom is the trace of hat matrix. In ridge regression, the hat matrix takes the form                                  . So the effective degree of freedom is the trace of this matrix.

b. EXTRA CREDIT: compute the Cp statistic using the effective degrees of freedom for p, for each of the few values that you tried.





4. Use LOESS to fit smooth to the relationship between infection risk and routine culturing ratio.

Try several different values of the smoothing parameter.

proc loess data=senic plots=residualsbysmooth(smooth);
model V4=V5 / smooth=0.1 0.3 0.5 0.8;
run;


























b. Also fit a generalized additive model with the infection risk again as the outcome and routine culturing ratio and number of beds as the predictors. Try several different choices of the effective degrees of freedom. Also try cross-validation. Choose one fit, and plot the residuals against the product of the two predictors.

proc gam data=senic;
model V4=spline(V5) spline(V7);
run;















PROC GAM DATA=senic;
MODEL V4 = SPLINE(V5,DF=5) SPLINE(V7,DF=10); 
RUN;

















PROC GAM DATA=senic;
MODEL V4 = SPLINE(V5,DF=10) SPLINE(V7,DF=5); 
RUN;











proc gam data=senic;
model V4=spline(V5) spline(V7) / method=gcv;
output out=gam predicted=predicted
run;

















And I choose the Cross Validation fit to plot the residuals against the product term.

data gam;
set gam;
residual=V4-predictedV4;
V5_V7=V5*V7;
run;
proc gplot data=gam;
plot residual*V5_V7;
run;


















5. Trees
Use enterprise miner to find a regression tree-based predictor for the infection-risk outcome. Try also a random forest.

















Regression tree:



























Random forest:














































b. Plot the predicted values from the two approaches against each other.

Here are parts of results of prediction values of Regression tree and random forest.
































and we get the plot:
